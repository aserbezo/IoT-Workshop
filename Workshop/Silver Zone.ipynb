{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a727584b-bf93-4735-94cd-b907fc7952e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType,TimestampType\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bb83301-80d9-40eb-8fd6-ab63494f9c1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_and_write_to_silver(bronze_path, silver_path, checkpoint_path):\n",
    "    try:\n",
    "        # Initialize Spark session\n",
    "        spark = SparkSession.builder.getOrCreate()\n",
    "        \n",
    "        # Step 1: Infer schema from existing files\n",
    "        static_df = spark.read.format(\"parquet\").load(bronze_path)\n",
    "        inferred_schema = static_df.schema\n",
    "        \n",
    "        # Step 2: Apply the inferred schema to the streaming DataFrame\n",
    "        bronze_df = spark.readStream \\\n",
    "            .format(\"parquet\") \\\n",
    "            .schema(inferred_schema) \\\n",
    "            .load(bronze_path)\n",
    "        \n",
    "        # Define a schema for transformation\n",
    "        schema = StructType([\n",
    "            StructField(\"temp\", IntegerType()),\n",
    "            StructField(\"tire_press\", IntegerType()),\n",
    "            StructField(\"speed\", IntegerType()),\n",
    "            StructField(\"alert\", StringType()),\n",
    "            StructField(\"Latitude\", DoubleType(), True),\n",
    "            StructField(\"Longitude\", DoubleType(), True),\n",
    "            StructField(\"DeviceId\", StringType()),\n",
    "            StructField(\"time\", TimestampType())\n",
    "        ])\n",
    "        \n",
    "        # Transform the DataFrame\n",
    "        silver_df = transform_dataframe(bronze_df, schema)\n",
    "        \n",
    "        # Write to Silver layer (Transformed data)\n",
    "        query = silver_df.writeStream \\\n",
    "            .format(\"parquet\") \\\n",
    "            .option(\"path\", silver_path) \\\n",
    "            .option(\"checkpointLocation\", checkpoint_path) \\\n",
    "            .start()\n",
    "        \n",
    "        # Await termination to keep the stream running\n",
    "        query.awaitTermination()\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "\n",
    "def transform_dataframe(df, schema):\n",
    "    df = df.withColumn(\"parsed\", from_json(\"body\", schema))\n",
    "    \n",
    "    # Now extract the values into separate columns\n",
    "    df = df.select(\n",
    "        col(\"parsed.temp\").alias(\"temp\"),\n",
    "        col(\"parsed.tire_press\").alias(\"tire_press\"),\n",
    "        col(\"parsed.speed\").alias(\"speed\"),\n",
    "        col(\"parsed.alert\").alias(\"alert\"),\n",
    "        col(\"parsed.Latitude\").alias(\"Latitude\"),\n",
    "        col(\"parsed.Longitude\").alias(\"Longitude\"),\n",
    "        col(\"parsed.DeviceId\").alias(\"DeviceId\"),\n",
    "        col(\"parsed.time\").alias(\"time\")\n",
    "    )\n",
    "    \n",
    "    df = df.withColumn(\"Fahrenheit\", col(\"temp\") * 9 / 5 + 32)\n",
    "    return df\n",
    "\n",
    "# Usage example\n",
    "bronze_path = \"/mnt/bronze\"\n",
    "silver_path = \"/mnt/silver\"\n",
    "checkpoint_path = \"/mnt/silver_checkpoint\"\n",
    "\n",
    "process_and_write_to_silver(bronze_path, silver_path, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5438839-bb91-4622-9c8c-bab8e4d59ab5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "119571ac-bb43-4bb7-91f6-9309250ba9fd",
     "origId": 1976721168456092,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver Zone",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
